{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-08 00:17:33.971758: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-08 00:17:34.005335: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736275654.041370   44924 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736275654.052716   44924 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-08 00:17:34.090921: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading regression datasets...\n",
      "\n",
      "Running AutoML on Diabetes Dataset (Regression)\n",
      "\n",
      "=== Diabetes Disease Progression Dataset ===\n",
      "Dataset shape: (442, 10)\n",
      "Number of unique target values: 214\n",
      "Detected task type: regression\n",
      "Score for linear with standard scaler: 55.9721\n",
      "Score for svr with standard scaler: 72.5375\n",
      "\n",
      "Best model: svr\n",
      "Best scaler: StandardScaler\n",
      "Best score: 72.5375\n",
      "\n",
      "Example Predictions (first 5 samples):\n",
      "Actual:    [219.  70. 202. 230. 111.]\n",
      "Predicted: [142.35294557 142.76997294 141.79521687 152.15746672 136.80688143]\n",
      "--------------------------------------------------\n",
      "\n",
      "Loading classification datasets...\n",
      "\n",
      "Running AutoML on Breast Cancer Dataset (Binary Classification)\n",
      "\n",
      "=== Breast Cancer Classification Dataset ===\n",
      "Dataset shape: (569, 30)\n",
      "Number of unique target values: 2\n",
      "Detected task type: classification\n",
      "Score for logistic with standard scaler: 0.9736\n",
      "Score for rf with standard scaler: 0.9560\n",
      "Score for svc with standard scaler: 0.9758\n",
      "Score for xgb with standard scaler: 0.9626\n",
      "Score for mlp with standard scaler: 0.9758\n",
      "\n",
      "Best model: svc\n",
      "Best scaler: StandardScaler\n",
      "Best score: 0.9758\n",
      "\n",
      "Example Predictions (first 5 samples):\n",
      "Actual:    [1 0 0 1 1]\n",
      "Predicted: [1 0 0 1 1]\n",
      "--------------------------------------------------\n",
      "\n",
      "Running AutoML on Digits Dataset (Multiclass Classification)\n",
      "\n",
      "=== Handwritten Digits Classification Dataset ===\n",
      "Dataset shape: (1797, 64)\n",
      "Number of unique target values: 10\n",
      "Detected task type: classification\n",
      "Score for logistic with standard scaler: 0.9617\n",
      "Score for rf with standard scaler: 0.9722\n",
      "Score for svc with standard scaler: 0.9770\n",
      "Score for xgb with standard scaler: 0.9541\n",
      "Score for mlp with standard scaler: 0.9722\n",
      "\n",
      "Best model: svc\n",
      "Best scaler: StandardScaler\n",
      "Best score: 0.9770\n",
      "\n",
      "Example Predictions (first 5 samples):\n",
      "Actual:    [6 9 3 7 2]\n",
      "Predicted: [6 9 3 7 2]\n",
      "--------------------------------------------------\n",
      "\n",
      "Running AutoML on Iris Dataset (Multiclass Classification)\n",
      "\n",
      "=== Iris Flower Classification Dataset ===\n",
      "Dataset shape: (150, 4)\n",
      "Number of unique target values: 3\n",
      "Detected task type: classification\n",
      "Score for logistic with standard scaler: 0.9583\n",
      "Score for rf with standard scaler: 0.9500\n",
      "Score for svc with standard scaler: 0.9500\n",
      "Score for xgb with standard scaler: 0.9333\n",
      "Score for mlp with standard scaler: 0.9417\n",
      "\n",
      "Best model: logistic\n",
      "Best scaler: StandardScaler\n",
      "Best score: 0.9583\n",
      "\n",
      "Example Predictions (first 5 samples):\n",
      "Actual:    [1 0 2 1 1]\n",
      "Predicted: [1 0 2 1 1]\n",
      "--------------------------------------------------\n",
      "\n",
      "Running AutoML on Wine Dataset (Multiclass Classification)\n",
      "\n",
      "=== Wine Classification Dataset ===\n",
      "Dataset shape: (178, 13)\n",
      "Number of unique target values: 3\n",
      "Detected task type: classification\n",
      "Score for logistic with standard scaler: 0.9791\n",
      "Score for rf with standard scaler: 0.9786\n",
      "Score for svc with standard scaler: 0.9719\n",
      "Score for xgb with standard scaler: 0.9433\n",
      "Score for mlp with standard scaler: 0.9648\n",
      "\n",
      "Best model: logistic\n",
      "Best scaler: StandardScaler\n",
      "Best score: 0.9791\n",
      "\n",
      "Example Predictions (first 5 samples):\n",
      "Actual:    [0 0 2 0 1]\n",
      "Predicted: [0 0 2 0 1]\n",
      "--------------------------------------------------\n",
      "\n",
      "=== Summary of Best Models ===\n",
      "\n",
      "Diabetes:\n",
      "Best Model: svr\n",
      "Best Scaler: StandardScaler\n",
      "Best Score: 72.5375\n",
      "\n",
      "Breast Cancer:\n",
      "Best Model: svc\n",
      "Best Scaler: StandardScaler\n",
      "Best Score: 0.9758\n",
      "\n",
      "Digits:\n",
      "Best Model: svc\n",
      "Best Scaler: StandardScaler\n",
      "Best Score: 0.9770\n",
      "\n",
      "Iris:\n",
      "Best Model: logistic\n",
      "Best Scaler: StandardScaler\n",
      "Best Score: 0.9583\n",
      "\n",
      "Wine:\n",
      "Best Model: logistic\n",
      "Best Scaler: StandardScaler\n",
      "Best Score: 0.9791\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import (load_diabetes, load_breast_cancer, \n",
    "                            load_digits, load_iris, load_wine)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from trainingSchool import TrainingSchool\n",
    "\n",
    "def run_experiment(X, y, dataset_name, is_sequential=False):\n",
    "    \"\"\"\n",
    "    Run AutoML pipeline on a dataset and print results\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== {dataset_name} ===\")\n",
    "    print(f\"Dataset shape: {X.shape}\")\n",
    "    print(f\"Number of unique target values: {len(np.unique(y))}\")\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Initialize and fit pipeline\n",
    "    pipeline = TrainingSchool()\n",
    "    pipeline.fit(X_train, y_train, sequence_data=is_sequential)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = pipeline.predict(X_test)\n",
    "    \n",
    "    # Print example predictions\n",
    "    print(\"\\nExample Predictions (first 5 samples):\")\n",
    "    print(f\"Actual:    {y_test[:5]}\")\n",
    "    print(f\"Predicted: {predictions[:5]}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "# Load regression datasets\n",
    "print(\"Loading regression datasets...\")\n",
    "\n",
    "# Diabetes dataset\n",
    "diabetes = load_diabetes()\n",
    "print(\"\\nRunning AutoML on Diabetes Dataset (Regression)\")\n",
    "diabetes_pipeline = run_experiment(\n",
    "    diabetes.data, diabetes.target,\n",
    "    \"Diabetes Disease Progression Dataset\"\n",
    ")\n",
    "\n",
    "# Load classification datasets\n",
    "print(\"\\nLoading classification datasets...\")\n",
    "\n",
    "# Breast Cancer dataset\n",
    "cancer = load_breast_cancer()\n",
    "print(\"\\nRunning AutoML on Breast Cancer Dataset (Binary Classification)\")\n",
    "cancer_pipeline = run_experiment(\n",
    "    cancer.data, cancer.target,\n",
    "    \"Breast Cancer Classification Dataset\"\n",
    ")\n",
    "\n",
    "# Digits dataset\n",
    "digits = load_digits()\n",
    "print(\"\\nRunning AutoML on Digits Dataset (Multiclass Classification)\")\n",
    "digits_pipeline = run_experiment(\n",
    "    digits.data, digits.target,\n",
    "    \"Handwritten Digits Classification Dataset\"\n",
    ")\n",
    "\n",
    "# Iris dataset\n",
    "iris = load_iris()\n",
    "print(\"\\nRunning AutoML on Iris Dataset (Multiclass Classification)\")\n",
    "iris_pipeline = run_experiment(\n",
    "    iris.data, iris.target,\n",
    "    \"Iris Flower Classification Dataset\"\n",
    ")\n",
    "\n",
    "# Wine dataset\n",
    "wine = load_wine()\n",
    "print(\"\\nRunning AutoML on Wine Dataset (Multiclass Classification)\")\n",
    "wine_pipeline = run_experiment(\n",
    "    wine.data, wine.target,\n",
    "    \"Wine Classification Dataset\"\n",
    ")\n",
    "\n",
    "# Print summary of best models for each dataset\n",
    "print(\"\\n=== Summary of Best Models ===\")\n",
    "datasets = {\n",
    "    \"Diabetes\": diabetes_pipeline,\n",
    "    \"Breast Cancer\": cancer_pipeline,\n",
    "    \"Digits\": digits_pipeline,\n",
    "    \"Iris\": iris_pipeline,\n",
    "    \"Wine\": wine_pipeline\n",
    "}\n",
    "\n",
    "for dataset_name, pipeline in datasets.items():\n",
    "    best_model_info = pipeline.get_best_model()\n",
    "    print(f\"\\n{dataset_name}:\")\n",
    "    print(f\"Best Model: {best_model_info['model_name']}\")\n",
    "    print(f\"Best Scaler: {type(best_model_info['scaler']).__name__}\")\n",
    "    print(f\"Best Score: {best_model_info['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_data.csv created!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a synthetic dataset\n",
    "np.random.seed(42)\n",
    "num_samples = 200\n",
    "X_synthetic = np.random.rand(num_samples, 5)  # 5 features\n",
    "y_synthetic = (X_synthetic.sum(axis=1) > 2.5).astype(int)  # A binary classification target\n",
    "\n",
    "df = pd.DataFrame(X_synthetic, columns=[f\"feature_{i}\" for i in range(X_synthetic.shape[1])])\n",
    "df[\"target\"] = y_synthetic\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"example_data.csv\", index=False)\n",
    "print(\"example_data.csv created!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset shape: (200, 6)\n",
      "Detected task type: classification\n",
      "Score for logistic with standard scaler: 0.9800\n",
      "Score for rf with standard scaler: 0.8650\n",
      "Score for svc with standard scaler: 0.9250\n",
      "Score for xgb with standard scaler: 0.8700\n",
      "Score for mlp with standard scaler: 0.9700\n",
      "\n",
      "Best model: logistic\n",
      "Best scaler: StandardScaler\n",
      "Best score: 0.9800\n",
      "\n",
      "Best Model Info:\n",
      "{'model': LogisticRegression(), 'scaler': StandardScaler(), 'score': 0.9800000000000001, 'model_name': 'logistic'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from trainingSchoolV2 import TrainingSchool\n",
    "\n",
    "# Load the CSV\n",
    "df_loaded = pd.read_csv(\"example_data.csv\")\n",
    "print(f\"Loaded dataset shape: {df_loaded.shape}\")\n",
    "\n",
    "# Split into features (X) and target (y)\n",
    "X = df_loaded.drop(\"target\", axis=1).values\n",
    "y = df_loaded[\"target\"].values\n",
    "\n",
    "# Initialize the TrainingSchool\n",
    "trainer = TrainingSchool()\n",
    "\n",
    "# Fit on the loaded data\n",
    "trainer.fit(X, y, sequence_data=False)  # or True if your data is sequential\n",
    "\n",
    "# The best model and scaler:\n",
    "best_model_info = trainer.get_best_model()\n",
    "print(\"\\nBest Model Info:\")\n",
    "print(best_model_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset shape: (200, 6)\n",
      "Detected task type: classification\n",
      "Score for logistic with standard scaler: 0.9800\n",
      "Score for rf with standard scaler: 0.8800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 19:50:12.811692: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for LSTM with standard scaler: 0.8800\n",
      "Score for Transformer with standard scaler: 0.5250\n",
      "\n",
      "Best model: logistic\n",
      "Best scaler: StandardScaler\n",
      "Best score: 0.9800\n",
      "\n",
      "Best Model Info:\n",
      "{'model': LogisticRegression(max_iter=1000), 'scaler': StandardScaler(), 'score': 0.9800000000000001, 'model_name': 'logistic'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from trainingSchool import TrainingSchool\n",
    "\n",
    "# Load the CSV\n",
    "df_loaded = pd.read_csv(\"example_data.csv\")\n",
    "print(f\"Loaded dataset shape: {df_loaded.shape}\")\n",
    "\n",
    "# Split into features (X) and target (y)\n",
    "X = df_loaded.drop(\"target\", axis=1).values\n",
    "y = df_loaded[\"target\"].values\n",
    "\n",
    "school = TrainingSchool('config.yaml')\n",
    "\n",
    "# Train on your data\n",
    "school.fit(X, y)\n",
    "\n",
    "best_model_info = school.get_best_model()\n",
    "print(\"\\nBest Model Info:\")\n",
    "print(best_model_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
