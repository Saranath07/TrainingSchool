{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-10 15:10:07.662202: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-10 15:10:07.694542: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736502007.716334  172210 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736502007.723199  172210 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-10 15:10:07.744810: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-10 15:10:10.675281: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "from processData import MLDataAnalyzer\n",
    "import pandas as pd\n",
    "from generateConfig import GenerateConfigLLM\n",
    "from trainingSchool import TrainingSchool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"example_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scalers:\n",
      "  StandardScaler:\n",
      "    name: StandardScaler\n",
      "    params: {}\n",
      "\n",
      "preprocessing:\n",
      "  missing_values:\n",
      "    strategy: ignore\n",
      "  categorical:\n",
      "    strategy: ignore\n",
      "  feature_selection:\n",
      "    enabled: false\n",
      "    method: recursive_feature_elimination\n",
      "    params: {}\n",
      "\n",
      "models:\n",
      "  classification:\n",
      "    LogisticRegression:\n",
      "      name: LogisticRegression\n",
      "      params: {}\n",
      "\n",
      "deep_learning:\n",
      "  lstm:\n",
      "    enabled: true\n",
      "    params:\n",
      "      units: [64, 32]\n",
      "      dropout_rates: [0.2, 0.2]\n",
      "      optimizer: adam\n",
      "      batch_size: 32\n",
      "      epochs: 100\n",
      "  \n",
      "  transformer:\n",
      "    enabled: true\n",
      "    params:\n",
      "      num_heads: 8\n",
      "      key_dim: 64\n",
      "      dropout_rate: 0.2\n",
      "      dense_units: [64, 32]\n",
      "      optimizer: adam\n",
      "      batch_size: 32\n",
      "      epochs: 100\n",
      "\n",
      "evaluation:\n",
      "  cv_folds: 5\n",
      "  stratify: false\n",
      "  metrics:\n",
      "    classification: ['accuracy', 'f1', 'precision', 'recall']\n",
      "\n",
      "sequence_data:\n",
      "  enabled: true\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "task_description = \"Using the dataframe I need a binary classification algorithm. This is a sequence data\"\n",
    "\n",
    "models = [\n",
    "    'StandardScaler',\n",
    "    'MinMaxScaler',\n",
    "    'RobustScaler',\n",
    "    'LinearRegression',\n",
    "    'Ridge',\n",
    "    'RandomForestRegressor',\n",
    "    'SVR',\n",
    "    'XGBRegressor',\n",
    "    'MLPRegressor',\n",
    "    'LogisticRegression',\n",
    "    'RandomForestClassifier',\n",
    "    'SVC',\n",
    "    'XGBClassifier',\n",
    "    'MLPClassifier'\n",
    "]\n",
    "\n",
    "\n",
    "analyzer = MLDataAnalyzer(df, \"target\", task_description)\n",
    "sample_data = analyzer.get_sample_data()\n",
    "analysis = analyzer.analyze_dataset()\n",
    "config_generator = GenerateConfigLLM()\n",
    "config = config_generator.generate_config(analysis, sample_data, task_description, models)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "def save_model(model, filepath):\n",
    "    \"\"\"\n",
    "    Save a trained model to a file using pickle.\n",
    "    \n",
    "    Parameters:\n",
    "    model: sklearn model object\n",
    "        The trained model to save\n",
    "    filepath: str\n",
    "        Path where the model will be saved\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'wb') as file:\n",
    "            pickle.dump(model, file)\n",
    "        print(f\"Model successfully saved to {filepath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving model: {str(e)}\")\n",
    "\n",
    "def load_model(filepath):\n",
    "    \"\"\"\n",
    "    Load a model from a pickle file.\n",
    "    \n",
    "    Parameters:\n",
    "    filepath: str\n",
    "        Path to the saved model file\n",
    "    \n",
    "    Returns:\n",
    "    The loaded model object\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'rb') as file:\n",
    "            model = pickle.load(file)\n",
    "        print(f\"Model successfully loaded from {filepath}\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_content = config.strip().strip('`').lstrip('yml').strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found. Running on CPU.\n",
      "Detected task type: classification\n",
      "Score for logistic_regression with standard scaler: 0.9800\n",
      "Score for LSTM with standard scaler: 0.9410\n",
      "Score for Transformer with standard scaler: 0.5250\n",
      "\n",
      "Best model: logistic_regression\n",
      "Best scaler: StandardScaler\n",
      "Best score: 0.9800\n",
      "Best Model Info: {'model': LogisticRegression(), 'scaler': StandardScaler(), 'score': 0.9800000000000001, 'model_name': 'logistic_regression'}\n"
     ]
    }
   ],
   "source": [
    " trainer = TrainingSchool(config_path=\"config1.yaml\")\n",
    "\n",
    "# Assuming X and y are your data\n",
    "# For demonstration, let's create dummy data:\n",
    "X = df.drop(\"target\", axis=1).values\n",
    "y = df[\"target\"].values\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "trainer.fit(X, y)\n",
    "\n",
    "# Retrieve and print best model details\n",
    "best_info = trainer.get_best_model()\n",
    "print(\"Best Model Info:\", best_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found. Running on CPU.\n",
      "Detected task type: classification\n",
      "Score for LogisticRegression with StandardScaler scaler: 0.9800\n",
      "Score for LSTM with StandardScaler scaler: 0.9355\n",
      "Score for Transformer with StandardScaler scaler: 0.5250\n",
      "\n",
      "Best model: LogisticRegression\n",
      "Best scaler: StandardScaler\n",
      "Best score: 0.9800\n",
      "Accuracy of the model: 0.99\n",
      "Model successfully saved to example_model.pkl\n",
      "Model successfully loaded from example_model.pkl\n",
      "{'filename': 'example.csv', 'task_description': 'Using the dataframe I need a binary classification algorithm. This is a sequence data', 'best_model': {'model_type': 'LogisticRegression', 'score': 0.9800000000000001, 'model_path': 'example_model.pkl'}, 'feature_columns': ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4']}\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "filename = \"example.csv\"\n",
    "\n",
    "with tempfile.NamedTemporaryFile(mode='w+', suffix='.yaml', delete=False) as temp_config_file:\n",
    "    temp_config_file.write(yaml_content)\n",
    "    temp_config_file.flush()\n",
    "    config_path = temp_config_file.name\n",
    "    \n",
    "    trainer = TrainingSchool(config_path=config_path)\n",
    "    X = df.drop(\"target\", axis=1).values\n",
    "    y = df[\"target\"].values\n",
    "    \n",
    "    trainer.fit(X, y)\n",
    "    best_info = trainer.get_best_model()\n",
    "    \n",
    "    # Save the actual model using joblib\n",
    "    model_filename = f\"{filename.rsplit('.', 1)[0]}_model.pkl\"\n",
    "\n",
    "    test_df = df.drop(\"target\", axis=1)\n",
    "\n",
    "    # Test the model\n",
    "    X_test = test_df[required_features].values\n",
    "    X_test_scaled = best_info['scaler'].transform(X_test)\n",
    "    predictions = best_info['model'].predict(X_test_scaled)\n",
    "\n",
    "    # Create a new DataFrame with predictions\n",
    "    result_df = test_df.copy()\n",
    "    result_df['target'] = predictions\n",
    "    y_test = model.predict(X_test_scaled)\n",
    "\n",
    "    print(\"Accuracy of the model:\", accuracy_score(y, y_test))\n",
    "\n",
    "    save_model(best_info['model'], model_filename)\n",
    "    \n",
    "    loaded_model = load_model(model_filename)\n",
    "\n",
    "    X_test_scaled = best_info['scaler'].transform(X_test)\n",
    "    predictions = best_info['model'].predict(X_test_scaled)\n",
    "\n",
    "\n",
    "    # Create a new DataFrame with predictions\n",
    "    result_df = test_df.copy()\n",
    "    result_df['target'] = predictions\n",
    "    y_test = loaded_model.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Create serializable model info\n",
    "    model_info = {\n",
    "        'filename': filename,\n",
    "        'task_description': task_description,\n",
    "        'best_model': {\n",
    "            'model_type': type(best_info['model']).__name__,\n",
    "            'score': best_info.get('score', None),\n",
    "            'model_path': model_filename  # Save the path to the saved model\n",
    "        },\n",
    "        'feature_columns': list(df.drop(\"target\", axis=1).columns)\n",
    "    }\n",
    "    \n",
    "    print(model_info)\n",
    "    \n",
    "    os.unlink(config_path)\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_df = df.drop(\"target\", axis=1)\n",
    "\n",
    "# X.to_csv(\"test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully loaded from example_model.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "required_features = model_info['feature_columns']\n",
    "if not all(feature in test_df.columns for feature in required_features):\n",
    "    print(jsonify({'error': 'Test data missing required features'}))\n",
    "\n",
    "model_path = \"example_model.pkl\"\n",
    "model = load_model(model_path)\n",
    "# Make predictions using the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df[required_features].values\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Create a new DataFrame with predictions\n",
    "result_df = test_df.copy()\n",
    "result_df['target'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.374540</td>\n",
       "      <td>0.950714</td>\n",
       "      <td>0.731994</td>\n",
       "      <td>0.598658</td>\n",
       "      <td>0.156019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.155995</td>\n",
       "      <td>0.058084</td>\n",
       "      <td>0.866176</td>\n",
       "      <td>0.601115</td>\n",
       "      <td>0.708073</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020584</td>\n",
       "      <td>0.969910</td>\n",
       "      <td>0.832443</td>\n",
       "      <td>0.212339</td>\n",
       "      <td>0.181825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.183405</td>\n",
       "      <td>0.304242</td>\n",
       "      <td>0.524756</td>\n",
       "      <td>0.431945</td>\n",
       "      <td>0.291229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.611853</td>\n",
       "      <td>0.139494</td>\n",
       "      <td>0.292145</td>\n",
       "      <td>0.366362</td>\n",
       "      <td>0.456070</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.262264</td>\n",
       "      <td>0.595078</td>\n",
       "      <td>0.051426</td>\n",
       "      <td>0.496366</td>\n",
       "      <td>0.596843</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.334244</td>\n",
       "      <td>0.770912</td>\n",
       "      <td>0.106598</td>\n",
       "      <td>0.075138</td>\n",
       "      <td>0.728189</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.495491</td>\n",
       "      <td>0.688402</td>\n",
       "      <td>0.434827</td>\n",
       "      <td>0.246402</td>\n",
       "      <td>0.819102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.799416</td>\n",
       "      <td>0.694696</td>\n",
       "      <td>0.272145</td>\n",
       "      <td>0.590231</td>\n",
       "      <td>0.360974</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.091582</td>\n",
       "      <td>0.917314</td>\n",
       "      <td>0.136819</td>\n",
       "      <td>0.950237</td>\n",
       "      <td>0.446006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature_0  feature_1  feature_2  feature_3  feature_4  target\n",
       "0     0.374540   0.950714   0.731994   0.598658   0.156019       1\n",
       "1     0.155995   0.058084   0.866176   0.601115   0.708073       1\n",
       "2     0.020584   0.969910   0.832443   0.212339   0.181825       1\n",
       "3     0.183405   0.304242   0.524756   0.431945   0.291229       1\n",
       "4     0.611853   0.139494   0.292145   0.366362   0.456070       1\n",
       "..         ...        ...        ...        ...        ...     ...\n",
       "195   0.262264   0.595078   0.051426   0.496366   0.596843       1\n",
       "196   0.334244   0.770912   0.106598   0.075138   0.728189       1\n",
       "197   0.495491   0.688402   0.434827   0.246402   0.819102       1\n",
       "198   0.799416   0.694696   0.272145   0.590231   0.360974       1\n",
       "199   0.091582   0.917314   0.136819   0.950237   0.446006       1\n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully saved to test_model\n"
     ]
    }
   ],
   "source": [
    "save_model(model, \"test_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully loaded from test_model\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model(\"test_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.475"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = loaded_model.predict(X_test)\n",
    "\n",
    "accuracy_score(y, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
