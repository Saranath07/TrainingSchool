{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-12 11:33:55.275270: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-12 11:33:55.287957: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736661835.303521  369197 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736661835.307845  369197 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-12 11:33:55.323872: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-12 11:33:57.478795: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "from processData import MLDataAnalyzer\n",
    "import pandas as pd\n",
    "from generateConfig import GenerateConfigLLM\n",
    "from trainingSchool import TrainingSchool "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"example_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```yml\n",
      "scalers:\n",
      "  standard_scaler:\n",
      "    name: StandardScaler\n",
      "    params: {}\n",
      "\n",
      "preprocessing:\n",
      "  missing_values:\n",
      "    strategy: None\n",
      "  categorical:\n",
      "    strategy: None\n",
      "  feature_selection:\n",
      "    enabled: False\n",
      "    method: None\n",
      "    params: {}\n",
      "\n",
      "models:\n",
      "  classification:\n",
      "    logistic_regression:\n",
      "      name: LogisticRegression\n",
      "      params: {}\n",
      "    random_forest_classifier:\n",
      "      name: RandomForestClassifier\n",
      "      params: {}\n",
      "\n",
      "deep_learning:\n",
      "  lstm:\n",
      "    enabled: True\n",
      "    params:\n",
      "      units: [64, 32]\n",
      "      dropout_rates: [0.2, 0.1]\n",
      "      optimizer: Adam\n",
      "      batch_size: 32\n",
      "      epochs: 10\n",
      "  transformer:\n",
      "    enabled: True\n",
      "    params:\n",
      "      num_heads: 2\n",
      "      key_dim: 32\n",
      "      dropout_rate: 0.1\n",
      "      dense_units: [64, 32]\n",
      "      optimizer: Adam\n",
      "      batch_size: 32\n",
      "      epochs: 10\n",
      "\n",
      "evaluation:\n",
      "  cv_folds: 5\n",
      "  stratify: False\n",
      "  metrics: \n",
      "    classification: ['accuracy', 'f1', 'precision', 'recall']\n",
      "\n",
      "sequence_data:\n",
      "  enabled: True\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "task_description = \"Using the dataframe I need a binary classification algorithm. This is a sequence data\"\n",
    "\n",
    "models = [\n",
    "    'StandardScaler',\n",
    "    'MinMaxScaler',\n",
    "    'RobustScaler',\n",
    "    'LinearRegression',\n",
    "    'Ridge',\n",
    "    'RandomForestRegressor',\n",
    "    'SVR',\n",
    "    'XGBRegressor',\n",
    "    'MLPRegressor',\n",
    "    'LogisticRegression',\n",
    "    'RandomForestClassifier',\n",
    "    'SVC',\n",
    "    'XGBClassifier',\n",
    "    'MLPClassifier'\n",
    "]\n",
    "\n",
    "\n",
    "analyzer = MLDataAnalyzer(df, \"target\", task_description)\n",
    "sample_data = analyzer.get_sample_data()\n",
    "analysis = analyzer.analyze_dataset()\n",
    "config_generator = GenerateConfigLLM()\n",
    "config = config_generator.generate_config(analysis, sample_data, task_description, models)\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "def save_model(model, filepath):\n",
    "    \"\"\"\n",
    "    Save a trained model to a file using pickle.\n",
    "    \n",
    "    Parameters:\n",
    "    model: sklearn model object\n",
    "        The trained model to save\n",
    "    filepath: str\n",
    "        Path where the model will be saved\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'wb') as file:\n",
    "            pickle.dump(model, file)\n",
    "        print(f\"Model successfully saved to {filepath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving model: {str(e)}\")\n",
    "\n",
    "def load_model(filepath):\n",
    "    \"\"\"\n",
    "    Load a model from a pickle file.\n",
    "    \n",
    "    Parameters:\n",
    "    filepath: str\n",
    "        Path to the saved model file\n",
    "    \n",
    "    Returns:\n",
    "    The loaded model object\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'rb') as file:\n",
    "            model = pickle.load(file)\n",
    "        print(f\"Model successfully loaded from {filepath}\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_content = config.strip().strip('`').lstrip('yml').strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found. Running on CPU.\n",
      "Detected task type: classification\n",
      "Score for logistic_regression with standard scaler: 0.9800\n",
      "Score for LSTM with standard scaler: 0.9493\n",
      "Score for Transformer with standard scaler: 0.5250\n",
      "\n",
      "Best model: logistic_regression\n",
      "Best scaler: StandardScaler\n",
      "Best score: 0.9800\n",
      "Best Model Info: {'model': LogisticRegression(), 'scaler': StandardScaler(), 'score': 0.9800000000000001, 'model_name': 'logistic_regression'}\n"
     ]
    }
   ],
   "source": [
    " trainer = TrainingSchool(config_path=\"config1.yaml\")\n",
    "\n",
    "# Assuming X and y are your data\n",
    "# For demonstration, let's create dummy data:\n",
    "X = df.drop(\"target\", axis=1).values\n",
    "y = df[\"target\"].values\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "trainer.fit(X, y)\n",
    "\n",
    "# Retrieve and print best model details\n",
    "best_info = trainer.get_best_model()\n",
    "print(\"Best Model Info:\", best_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found. Running on CPU.\n",
      "Detected task type: classification\n",
      "Score for logistic_regression with standard_scaler scaler: 0.9800\n",
      "Score for random_forest_classifier with standard_scaler scaler: 0.8750\n",
      "Score for LSTM with standard_scaler scaler: 0.8625\n",
      "Score for Transformer with standard_scaler scaler: 0.5250\n",
      "\n",
      "Best model: logistic_regression\n",
      "Best scaler: StandardScaler\n",
      "Best score: 0.9800\n",
      "Model successfully saved to example_model.pkl\n",
      "Model successfully loaded from example_model.pkl\n",
      "{'filename': 'example.csv', 'task_description': 'Using the dataframe I need a binary classification algorithm. This is a sequence data', 'best_model': {'model_type': 'LogisticRegression', 'score': 0.9800000000000001, 'model_path': 'example_model.pkl'}, 'feature_columns': ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4']}\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "filename = \"example.csv\"\n",
    "\n",
    "with tempfile.NamedTemporaryFile(mode='w+', suffix='.yaml', delete=False) as temp_config_file:\n",
    "    temp_config_file.write(yaml_content)\n",
    "    temp_config_file.flush()\n",
    "    config_path = temp_config_file.name\n",
    "    \n",
    "    trainer = TrainingSchool(config_path=config_path)\n",
    "    X = df.drop(\"target\", axis=1).values\n",
    "    y = df[\"target\"].values\n",
    "    \n",
    "    trainer.fit(X, y)\n",
    "    best_info = trainer.get_best_model()\n",
    "    \n",
    "    # Save the actual model using joblib\n",
    "    model_filename = f\"{filename.rsplit('.', 1)[0]}_model.pkl\"\n",
    "\n",
    "    test_df = df.drop(\"target\", axis=1)\n",
    "\n",
    "    model_info = {\n",
    "        'filename': filename,\n",
    "        'task_description': task_description,\n",
    "        'best_model': {\n",
    "            'model_type': type(best_info['model']).__name__,\n",
    "            'score': best_info.get('score', None),\n",
    "            'model_path': model_filename  # Save the path to the saved model\n",
    "        },\n",
    "        'feature_columns': list(df.drop(\"target\", axis=1).columns)\n",
    "    }\n",
    "\n",
    "\n",
    "    required_features = model_info['feature_columns']\n",
    "    if not all(feature in test_df.columns for feature in required_features):\n",
    "        print(jsonify({'error': 'Test data missing required features'}))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    save_model(best_info['model'], model_filename)\n",
    "    \n",
    "    loaded_model = load_model(model_filename)\n",
    "\n",
    "    X_test_scaled = best_info['scaler'].transform(X_test)\n",
    "    predictions = best_info['model'].predict(X_test_scaled)\n",
    "\n",
    "\n",
    "    # Create a new DataFrame with predictions\n",
    "    result_df = test_df.copy()\n",
    "    result_df['target'] = predictions\n",
    "    y_test = loaded_model.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    # Create serializable model info\n",
    "   \n",
    "    \n",
    "    print(model_info)\n",
    "    \n",
    "    os.unlink(config_path)\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_df = df.drop(\"target\", axis=1)\n",
    "\n",
    "# X.to_csv(\"test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully loaded from example_model.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "model_path = \"example_model.pkl\"\n",
    "model = load_model(model_path)\n",
    "# Make predictions using the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.374540</td>\n",
       "      <td>0.950714</td>\n",
       "      <td>0.731994</td>\n",
       "      <td>0.598658</td>\n",
       "      <td>0.156019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.155995</td>\n",
       "      <td>0.058084</td>\n",
       "      <td>0.866176</td>\n",
       "      <td>0.601115</td>\n",
       "      <td>0.708073</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020584</td>\n",
       "      <td>0.969910</td>\n",
       "      <td>0.832443</td>\n",
       "      <td>0.212339</td>\n",
       "      <td>0.181825</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.183405</td>\n",
       "      <td>0.304242</td>\n",
       "      <td>0.524756</td>\n",
       "      <td>0.431945</td>\n",
       "      <td>0.291229</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.611853</td>\n",
       "      <td>0.139494</td>\n",
       "      <td>0.292145</td>\n",
       "      <td>0.366362</td>\n",
       "      <td>0.456070</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.262264</td>\n",
       "      <td>0.595078</td>\n",
       "      <td>0.051426</td>\n",
       "      <td>0.496366</td>\n",
       "      <td>0.596843</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.334244</td>\n",
       "      <td>0.770912</td>\n",
       "      <td>0.106598</td>\n",
       "      <td>0.075138</td>\n",
       "      <td>0.728189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.495491</td>\n",
       "      <td>0.688402</td>\n",
       "      <td>0.434827</td>\n",
       "      <td>0.246402</td>\n",
       "      <td>0.819102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.799416</td>\n",
       "      <td>0.694696</td>\n",
       "      <td>0.272145</td>\n",
       "      <td>0.590231</td>\n",
       "      <td>0.360974</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.091582</td>\n",
       "      <td>0.917314</td>\n",
       "      <td>0.136819</td>\n",
       "      <td>0.950237</td>\n",
       "      <td>0.446006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature_0  feature_1  feature_2  feature_3  feature_4  target\n",
       "0     0.374540   0.950714   0.731994   0.598658   0.156019       1\n",
       "1     0.155995   0.058084   0.866176   0.601115   0.708073       0\n",
       "2     0.020584   0.969910   0.832443   0.212339   0.181825       0\n",
       "3     0.183405   0.304242   0.524756   0.431945   0.291229       0\n",
       "4     0.611853   0.139494   0.292145   0.366362   0.456070       0\n",
       "..         ...        ...        ...        ...        ...     ...\n",
       "195   0.262264   0.595078   0.051426   0.496366   0.596843       0\n",
       "196   0.334244   0.770912   0.106598   0.075138   0.728189       0\n",
       "197   0.495491   0.688402   0.434827   0.246402   0.819102       1\n",
       "198   0.799416   0.694696   0.272145   0.590231   0.360974       1\n",
       "199   0.091582   0.917314   0.136819   0.950237   0.446006       0\n",
       "\n",
       "[200 rows x 6 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Working outside of request context.\n\nThis typically means that you attempted to use functionality that needed\nan active HTTP request. Consult the documentation on testing for\ninformation about how to avoid this problem.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# 9. Generate output filename\u001b[39;00m\n\u001b[1;32m     15\u001b[0m output_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictions_1.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[43msend_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemp_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmimetype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext/csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_attachment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_filename\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/flask/helpers.py:507\u001b[0m, in \u001b[0;36msend_file\u001b[0;34m(path_or_file, mimetype, as_attachment, download_name, conditional, etag, last_modified, max_age)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_file\u001b[39m(\n\u001b[1;32m    394\u001b[0m     path_or_file: os\u001b[38;5;241m.\u001b[39mPathLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m t\u001b[38;5;241m.\u001b[39mBinaryIO,\n\u001b[1;32m    395\u001b[0m     mimetype: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    401\u001b[0m     max_age: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m (\u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m t\u001b[38;5;241m.\u001b[39mCallable[[\u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m], \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m]) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    402\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response:\n\u001b[1;32m    403\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Send the contents of a file to the client.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \n\u001b[1;32m    405\u001b[0m \u001b[38;5;124;03m    The first argument can be a file path or a file-like object. Paths\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 0.2\u001b[39;00m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m werkzeug\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39msend_file(  \u001b[38;5;66;03m# type: ignore[return-value]\u001b[39;00m\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_prepare_send_file_kwargs(\n\u001b[1;32m    506\u001b[0m             path_or_file\u001b[38;5;241m=\u001b[39mpath_or_file,\n\u001b[0;32m--> 507\u001b[0m             environ\u001b[38;5;241m=\u001b[39m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m,\n\u001b[1;32m    508\u001b[0m             mimetype\u001b[38;5;241m=\u001b[39mmimetype,\n\u001b[1;32m    509\u001b[0m             as_attachment\u001b[38;5;241m=\u001b[39mas_attachment,\n\u001b[1;32m    510\u001b[0m             download_name\u001b[38;5;241m=\u001b[39mdownload_name,\n\u001b[1;32m    511\u001b[0m             conditional\u001b[38;5;241m=\u001b[39mconditional,\n\u001b[1;32m    512\u001b[0m             etag\u001b[38;5;241m=\u001b[39metag,\n\u001b[1;32m    513\u001b[0m             last_modified\u001b[38;5;241m=\u001b[39mlast_modified,\n\u001b[1;32m    514\u001b[0m             max_age\u001b[38;5;241m=\u001b[39mmax_age,\n\u001b[1;32m    515\u001b[0m         )\n\u001b[1;32m    516\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/werkzeug/local.py:311\u001b[0m, in \u001b[0;36m_ProxyLookup.__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 311\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_current_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m:\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfallback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/werkzeug/local.py:508\u001b[0m, in \u001b[0;36mLocalProxy.__init__.<locals>._get_current_object\u001b[0;34m()\u001b[0m\n\u001b[1;32m    506\u001b[0m     obj \u001b[38;5;241m=\u001b[39m local\u001b[38;5;241m.\u001b[39mget()\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m:\n\u001b[0;32m--> 508\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(unbound_message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m get_name(obj)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Working outside of request context.\n\nThis typically means that you attempted to use functionality that needed\nan active HTTP request. Consult the documentation on testing for\ninformation about how to avoid this problem."
     ]
    }
   ],
   "source": [
    "from flask import send_file\n",
    "\n",
    "result_df = test_df.copy()\n",
    "result_df['target'] = predictions\n",
    "\n",
    "# 7. Create a temporary file to store the CSV\n",
    "temp_file = tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False, newline='')\n",
    "result_df.to_csv(temp_file.name, index=False)\n",
    "temp_file_path = temp_file.name\n",
    "temp_file.close()\n",
    "\n",
    "model_name = \"LogisticRegression\"\n",
    "\n",
    "# 9. Generate output filename\n",
    "output_filename = f\"predictions_1.csv\"\n",
    "\n",
    "send_file(\n",
    "    temp_file_path,\n",
    "    mimetype='text/csv',\n",
    "    as_attachment=True,\n",
    "    download_name=output_filename\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-12 11:35:30.823604: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-12 11:35:30.841867: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736661930.859340  369989 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736661930.864389  369989 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-12 11:35:30.881460: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-12 11:35:33.559228: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "INFO:httpx:HTTP Request: POST https://api.together.xyz/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Starting iteration 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scalers:\n",
      "  standard_scaler:\n",
      "    name: StandardScaler\n",
      "    params: {}\n",
      "\n",
      "preprocessing:\n",
      "  missing_values:\n",
      "    strategy: None\n",
      "  categorical:\n",
      "    strategy: None\n",
      "  feature_selection:\n",
      "    enabled: false\n",
      "    method: None\n",
      "    params: {}\n",
      "\n",
      "models:\n",
      "  regression:\n",
      "    linear_regression:\n",
      "      name: LinearRegression\n",
      "      params: {}\n",
      "    ridge_regression:\n",
      "      name: Ridge\n",
      "      params: {}\n",
      "    random_forest_regressor:\n",
      "      name: RandomForestRegressor\n",
      "      params: {\"n_estimators\": 100, \"max_depth\": 5}\n",
      "    xgb_regressor:\n",
      "      name: XGBRegressor\n",
      "      params: {\"n_estimators\": 100, \"max_depth\": 5}\n",
      "    mlp_regressor:\n",
      "      name: MLPRegressor\n",
      "      params: {\"hidden_layer_sizes\": [10]}\n",
      "\n",
      "deep_learning:\n",
      "  lstm:\n",
      "    enabled: false\n",
      "    params: {}\n",
      "  transformer:\n",
      "    enabled: false\n",
      "    params: {}\n",
      "\n",
      "evaluation:\n",
      "  cv_folds: 5\n",
      "  stratify: false\n",
      "  metrics: \n",
      "    regression: [\"mean_squared_error\", \"mean_absolute_error\", \"r2_score\"]\n",
      "\n",
      "sequence_data:\n",
      "  enabled: false\n",
      "No GPU found. Running on CPU.\n",
      "Detected task type: classification\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'classification'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m      7\u001b[0m trainer \u001b[38;5;241m=\u001b[39m IterativeModelTrainer(\n\u001b[1;32m      8\u001b[0m     df\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m      9\u001b[0m     task_description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour task description\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     max_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Run training\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m iterations, best_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_iteratively\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m     17\u001b[0m X_test \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[0;32m~/TrainingSchool/Pipeline/main.py:151\u001b[0m, in \u001b[0;36mIterativeModelTrainer.train_iteratively\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    146\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting iteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00miteration\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iterations\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# Train and evaluate models\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m results, iteration_best \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43myaml_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# Generate performance report\u001b[39;00m\n\u001b[1;32m    156\u001b[0m performance_report \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_analyzer\u001b[38;5;241m.\u001b[39mgenerate_performance_report(\n\u001b[1;32m    157\u001b[0m     results,\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y)) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    159\u001b[0m )\n",
      "File \u001b[0;32m~/TrainingSchool/Pipeline/main.py:75\u001b[0m, in \u001b[0;36mIterativeModelTrainer._train_and_evaluate\u001b[0;34m(self, config_yaml, X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[1;32m     72\u001b[0m temp_file\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m     74\u001b[0m trainer \u001b[38;5;241m=\u001b[39m TrainingSchool(config_path\u001b[38;5;241m=\u001b[39mtemp_file\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m---> 75\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model_info \u001b[38;5;129;01min\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/TrainingSchool/Pipeline/trainingSchool.py:235\u001b[0m, in \u001b[0;36mTrainingSchool.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    233\u001b[0m     active_models \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregression_models\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassification_models \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_models\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclassification\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m     active_models \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassification_models\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# Initialize tracking variables for best model\u001b[39;00m\n",
      "File \u001b[0;32m~/TrainingSchool/Pipeline/trainingSchool.py:97\u001b[0m, in \u001b[0;36mTrainingSchool._initialize_models\u001b[0;34m(self, task_type)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initialize models based on task type from config\"\"\"\u001b[39;00m\n\u001b[1;32m     96\u001b[0m models \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 97\u001b[0m model_configs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtask_type\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model_config \u001b[38;5;129;01min\u001b[39;00m model_configs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    100\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_class_from_string(model_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'classification'"
     ]
    }
   ],
   "source": [
    "from main import IterativeModelTrainer\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('example_data.csv')\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = IterativeModelTrainer(\n",
    "    df=df,\n",
    "    task_description=\"Your task description\",\n",
    "    max_iterations=2\n",
    ")\n",
    "\n",
    "# Run training\n",
    "iterations, best_model = trainer.train_iteratively()\n",
    "\n",
    "# Make predictions\n",
    "X_test = df.drop(\"target\", axis=1).values\n",
    "predictions = best_model['model'].predict(best_model['scaler'].transform(X_test))\n",
    "\n",
    "# Create results DataFrame\n",
    "results = pd.DataFrame(predictions, columns=['predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-12 12:27:34.447279: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-12 12:27:34.458194: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736665054.472838  395974 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736665054.477075  395974 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-12 12:27:34.491509: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-12 12:27:37.412748: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tempfile\n",
    "from processData import MLDataAnalyzer\n",
    "from generateConfig import GenerateConfigLLM\n",
    "from model_analysis import ModelAnalysisLLM  \n",
    "from trainingSchool import TrainingSchool \n",
    "import logging\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class IterativeModelTrainer:\n",
    "    def __init__(self, df, task_description, target_column=\"target\", max_iterations=2):\n",
    "        self.df = df\n",
    "        self.task_description = task_description\n",
    "        self.target_column = target_column\n",
    "        self.max_iterations = max_iterations\n",
    "        self.analyzer = MLDataAnalyzer(df, target_column, task_description)\n",
    "        self.model_analyzer = ModelAnalysisLLM()\n",
    "        self.config_generator = GenerateConfigLLM()  # Add initial config generator\n",
    "        self.available_models = [\n",
    "            'StandardScaler', 'MinMaxScaler', 'RobustScaler',\n",
    "            'LinearRegression', 'Ridge', 'RandomForestRegressor',\n",
    "            'SVR', 'XGBRegressor', 'MLPRegressor',\n",
    "            'LogisticRegression', 'RandomForestClassifier',\n",
    "            'SVC', 'XGBClassifier', 'MLPClassifier'\n",
    "        ]\n",
    "        \n",
    "    def _train_and_evaluate(self, config_yaml, X_train, X_test, y_train, y_test):\n",
    "        \"\"\"Train models and collect performance metrics\"\"\"\n",
    "        with tempfile.NamedTemporaryFile(mode='w+', suffix='.yaml', delete=False) as temp_file:\n",
    "            temp_file.write(config_yaml)\n",
    "            temp_file.flush()\n",
    "            \n",
    "            trainer = TrainingSchool(config_path=temp_file.name)\n",
    "            trainer.fit(X_train, y_train)\n",
    "            \n",
    "            results = {}\n",
    "            for model_name, model_info in trainer.models.items():\n",
    "                model = model_info['model']\n",
    "                scaler = model_info['scaler']\n",
    "                \n",
    "                # Time the training\n",
    "                start_time = time.time()\n",
    "                model.fit(scaler.transform(X_train), y_train)\n",
    "                training_time = time.time() - start_time\n",
    "                \n",
    "                # Time the prediction\n",
    "                start_time = time.time()\n",
    "                y_pred = model.predict(scaler.transform(X_test))\n",
    "                prediction_time = time.time() - start_time\n",
    "                \n",
    "                # Get memory usage\n",
    "                memory_usage = sys.getsizeof(model) + sys.getsizeof(scaler)\n",
    "                \n",
    "                # Collect CV scores\n",
    "                cv_scores = trainer.get_cv_scores(model_name)\n",
    "                \n",
    "                # Get feature importance if available\n",
    "                feature_importance = None\n",
    "                if hasattr(model, 'feature_importances_'):\n",
    "                    feature_importance = dict(zip(\n",
    "                        self.df.drop(self.target_column, axis=1).columns,\n",
    "                        model.feature_importances_\n",
    "                    ))\n",
    "                \n",
    "                results[model_name] = {\n",
    "                    'y_true': y_test,\n",
    "                    'y_pred': y_pred,\n",
    "                    'cv_scores': cv_scores,\n",
    "                    'training_time': training_time,\n",
    "                    'prediction_time': prediction_time,\n",
    "                    'memory_usage': memory_usage,\n",
    "                    'feature_importance': feature_importance,\n",
    "                    'convergence_info': {\n",
    "                        'n_iter_': getattr(model, 'n_iter_', None),\n",
    "                        'loss_curve_': getattr(model, 'loss_curve_', None)\n",
    "                    }\n",
    "                }\n",
    "            \n",
    "            os.unlink(temp_file.name)\n",
    "            return results, trainer.get_best_model()\n",
    "    \n",
    "    def train_iteratively(self):\n",
    "        \"\"\"Perform iterative training with model analysis and refinement\"\"\"\n",
    "        # Initial analysis and data split\n",
    "        analysis = self.analyzer.analyze_dataset()\n",
    "        sample_data = self.analyzer.get_sample_data()\n",
    "        X = self.df.drop(self.target_column, axis=1).values\n",
    "        y = self.df[self.target_column].values\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Storage for tracking progress\n",
    "        all_iterations = []\n",
    "        best_model_info = None\n",
    "        best_score = float('-inf')\n",
    "        \n",
    "        # Get initial configuration using GenerateConfigLLM\n",
    "        initial_config = self.config_generator.generate_config(\n",
    "            analysis, sample_data, self.task_description, self.available_models\n",
    "        )\n",
    "        yaml_content = initial_config.strip().strip('`').lstrip('yml').strip()\n",
    "\n",
    "        print(self.task_description)\n",
    "\n",
    "        print(yaml_content)\n",
    "        \n",
    "        # First iteration with initial configuration\n",
    "        logging.info(\"Starting first iteration with GenerateConfigLLM configuration\")\n",
    "        results, iteration_best = self._train_and_evaluate(\n",
    "            yaml_content, X_train, X_test, y_train, y_test\n",
    "        )\n",
    "\n",
    "        print(results)\n",
    "        \n",
    "\n",
    "        # Generate performance report\n",
    "        performance_report = self.model_analyzer.generate_performance_report(\n",
    "            results,\n",
    "            'classification' if len(np.unique(y)) <= 10 else 'regression'\n",
    "        )\n",
    "        \n",
    "        # Store first iteration results\n",
    "        iteration_info = {\n",
    "            'iteration': 1,\n",
    "            'config': yaml_content,\n",
    "            'results': results,\n",
    "            'best_model': iteration_best,\n",
    "            'performance_report': performance_report\n",
    "        }\n",
    "        all_iterations.append(iteration_info)\n",
    "        \n",
    "        # Update best model\n",
    "        best_score = iteration_best['score']\n",
    "        best_model_info = iteration_best\n",
    "        \n",
    "        logging.info(f\"Completed first iteration with score: {best_score}\")\n",
    "        \n",
    "        # Continue with remaining iterations using ModelAnalysisLLM\n",
    "        current_config = yaml_content\n",
    "        for iteration in range(1, self.max_iterations):\n",
    "            logging.info(f\"Starting iteration {iteration + 1}/{self.max_iterations}\")\n",
    "            \n",
    "            # Generate refined configuration\n",
    "            current_config = self.model_analyzer.generate_refined_config(\n",
    "                analysis,\n",
    "                results,\n",
    "                'classification' if len(np.unique(y)) <= 10 else 'regression',\n",
    "                self.available_models\n",
    "            )\n",
    "            \n",
    "            # Train and evaluate models\n",
    "            results, iteration_best = self._train_and_evaluate(\n",
    "                current_config, X_train, X_test, y_train, y_test\n",
    "            )\n",
    "\n",
    "            print(\"Results\")\n",
    "\n",
    "            print(results)\n",
    "\n",
    "            return\n",
    "            \n",
    "            # Generate performance report\n",
    "            performance_report = self.model_analyzer.generate_performance_report(\n",
    "                results,\n",
    "                'classification' if len(np.unique(y)) <= 10 else 'regression'\n",
    "            )\n",
    "            \n",
    "            # Store iteration results\n",
    "            iteration_info = {\n",
    "                'iteration': iteration + 1,\n",
    "                'config': current_config,\n",
    "                'results': results,\n",
    "                'best_model': iteration_best,\n",
    "                'performance_report': performance_report\n",
    "            }\n",
    "            all_iterations.append(iteration_info)\n",
    "            \n",
    "            # Update best model if better\n",
    "            if iteration_best['score'] > best_score:\n",
    "                best_score = iteration_best['score']\n",
    "                best_model_info = iteration_best\n",
    "            \n",
    "            logging.info(f\"Completed iteration {iteration + 1} with best score: {best_score}\")\n",
    "        \n",
    "        return all_iterations, best_model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the dataframe I need a binary classification algorithm\n",
      "scalers:\n",
      "  standard_scaler:\n",
      "    name: StandardScaler\n",
      "    params: {}\n",
      "\n",
      "preprocessing:\n",
      "  missing_values:\n",
      "    strategy: None\n",
      "  categorical:\n",
      "    strategy: None\n",
      "  feature_selection:\n",
      "    enabled: false\n",
      "    method: None\n",
      "    params: {}\n",
      "\n",
      "models:\n",
      "  classification:\n",
      "    logistic_regression:\n",
      "      name: LogisticRegression\n",
      "      params:\n",
      "        penalty: 'l2'\n",
      "        C: 1.0\n",
      "        random_state: 42\n",
      "    random_forest:\n",
      "      name: RandomForestClassifier\n",
      "      params:\n",
      "        n_estimators: 100\n",
      "        max_depth: 5\n",
      "        random_state: 42\n",
      "    xgb_classifier:\n",
      "      name: XGBClassifier\n",
      "      params:\n",
      "        n_estimators: 100\n",
      "        max_depth: 5\n",
      "        learning_rate: 0.1\n",
      "        random_state: 42\n",
      "\n",
      "deep_learning:\n",
      "  lstm:\n",
      "    enabled: false\n",
      "    params:\n",
      "      units: []\n",
      "      dropout_rates: []\n",
      "      optimizer: None\n",
      "      batch_size: 32\n",
      "      epochs: 10\n",
      "  transformer:\n",
      "    enabled: false\n",
      "    params:\n",
      "      num_heads: 8\n",
      "      key_dim: 64\n",
      "      dropout_rate: 0.1\n",
      "      dense_units: []\n",
      "      optimizer: None\n",
      "      batch_size: 32\n",
      "      epochs: 10\n",
      "  mlp_classifier:\n",
      "    enabled: true\n",
      "    params:\n",
      "      hidden_layer_sizes: [64, 32]\n",
      "      activation: 'relu'\n",
      "      solver: 'adam'\n",
      "      batch_size: 32\n",
      "      epochs: 10\n",
      "\n",
      "evaluation:\n",
      "  cv_folds: 5\n",
      "  stratify: false\n",
      "  metrics:\n",
      "    classification:\n",
      "      - accuracy\n",
      "      - f1\n",
      "      - precision\n",
      "      - recall\n",
      "\n",
      "sequence_data:\n",
      "  enabled: false\n",
      "No GPU found. Running on CPU.\n",
      "Detected task type: classification\n",
      "Score for logistic_regression with standard_scaler scaler: 0.9688\n",
      "Score for random_forest with standard_scaler scaler: 0.8625\n",
      "Score for xgb_classifier with standard_scaler scaler: 0.8438\n",
      "\n",
      "Best model: logistic_regression\n",
      "Best scaler: StandardScaler\n",
      "Best score: 0.9688\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'model_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m      5\u001b[0m trainer \u001b[38;5;241m=\u001b[39m IterativeModelTrainer(\n\u001b[1;32m      6\u001b[0m     df\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m      7\u001b[0m     task_description\u001b[38;5;241m=\u001b[39mtask_description,\n\u001b[1;32m      8\u001b[0m     max_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m  \n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Run training\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m iterations, best_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_iteratively\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 122\u001b[0m, in \u001b[0;36mIterativeModelTrainer.train_iteratively\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m results, iteration_best \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_and_evaluate(\n\u001b[1;32m    117\u001b[0m     yaml_content, X_train, X_test, y_train, y_test\n\u001b[1;32m    118\u001b[0m )\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Generate performance report\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m performance_report \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_analyzer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_performance_report\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclassification\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mregression\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m    125\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# Store first iteration results\u001b[39;00m\n\u001b[1;32m    128\u001b[0m iteration_info \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124miteration\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m'\u001b[39m: yaml_content,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mperformance_report\u001b[39m\u001b[38;5;124m'\u001b[39m: performance_report\n\u001b[1;32m    134\u001b[0m }\n",
      "File \u001b[0;32m~/TrainingSchool/Pipeline/model_analysis.py:192\u001b[0m, in \u001b[0;36mModelAnalysisLLM.generate_performance_report\u001b[0;34m(self, performance_metrics, task_type)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"Generate a detailed performance report with insights and recommendations\"\"\"\u001b[39;00m\n\u001b[1;32m    156\u001b[0m         template \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'''\u001b[39m\u001b[38;5;124mAs an ML expert, analyze the following model performance results and provide detailed insights:\u001b[39m\n\u001b[1;32m    157\u001b[0m \n\u001b[1;32m    158\u001b[0m \u001b[38;5;124mPerformance Metrics:\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m \n\u001b[1;32m    187\u001b[0m \u001b[38;5;124mFormat the report in a clear, structured manner with specific examples and evidence.\u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m    189\u001b[0m         prompt \u001b[38;5;241m=\u001b[39m template\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    190\u001b[0m             performance_details\u001b[38;5;241m=\u001b[39mjson\u001b[38;5;241m.\u001b[39mdumps(\n\u001b[1;32m    191\u001b[0m                 [{\n\u001b[0;32m--> 192\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m,\n\u001b[1;32m    193\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m'\u001b[39m: m\u001b[38;5;241m.\u001b[39mmetrics,\n\u001b[1;32m    194\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mefficiency\u001b[39m\u001b[38;5;124m'\u001b[39m: {\n\u001b[1;32m    195\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_time\u001b[39m\u001b[38;5;124m'\u001b[39m: m\u001b[38;5;241m.\u001b[39mtraining_time,\n\u001b[1;32m    196\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction_time\u001b[39m\u001b[38;5;124m'\u001b[39m: m\u001b[38;5;241m.\u001b[39mprediction_time,\n\u001b[1;32m    197\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmemory_usage\u001b[39m\u001b[38;5;124m'\u001b[39m: m\u001b[38;5;241m.\u001b[39mmemory_usage\n\u001b[1;32m    198\u001b[0m                     },\n\u001b[1;32m    199\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconvergence\u001b[39m\u001b[38;5;124m'\u001b[39m: m\u001b[38;5;241m.\u001b[39mconvergence_info,\n\u001b[1;32m    200\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_importance\u001b[39m\u001b[38;5;124m'\u001b[39m: m\u001b[38;5;241m.\u001b[39mfeature_importance\n\u001b[1;32m    201\u001b[0m                 } \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m performance_metrics],\n\u001b[1;32m    202\u001b[0m                 indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    203\u001b[0m             ),\n\u001b[1;32m    204\u001b[0m             task_type\u001b[38;5;241m=\u001b[39mtask_type\n\u001b[1;32m    205\u001b[0m         )\n\u001b[1;32m    207\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minvoke(prompt)\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'model_name'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"example_data.csv\")\n",
    "\n",
    "task_description = \"Using the dataframe I need a binary classification algorithm\"\n",
    "\n",
    "trainer = IterativeModelTrainer(\n",
    "    df=df,\n",
    "    task_description=task_description,\n",
    "    max_iterations=2  \n",
    ")\n",
    "\n",
    "# Run training\n",
    "iterations, best_model = trainer.train_iteratively()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
